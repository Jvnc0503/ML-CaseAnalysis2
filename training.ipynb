{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f7dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c63806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('used_cars_clean.csv')\n",
    "x = df.drop(columns=['price'], axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2727ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log1p(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_log, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f66815",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Hyundai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_19228\\3291291970.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m     max_iter=\u001b[32m300\u001b[39m,\n\u001b[32m      5\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model.fit(x_train, y_train)\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1359\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m                 )\n\u001b[32m   1362\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight, X_val, y_val, sample_weight_val)\u001b[39m\n\u001b[32m    560\u001b[39m         acc_apply_split_time = \u001b[32m0.0\u001b[39m  \u001b[38;5;66;03m# time spent splitting nodes\u001b[39;00m\n\u001b[32m    561\u001b[39m         acc_compute_hist_time = \u001b[32m0.0\u001b[39m  \u001b[38;5;66;03m# time spent computing histograms\u001b[39;00m\n\u001b[32m    562\u001b[39m         \u001b[38;5;66;03m# time spent predicting X for gradient and hessians update\u001b[39;00m\n\u001b[32m    563\u001b[39m         acc_prediction_time = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m         X, known_categories = self._preprocess_X(X, reset=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    565\u001b[39m         y = _check_y(y, estimator=self)\n\u001b[32m    566\u001b[39m         y = self._encode_y(y)\n\u001b[32m    567\u001b[39m         check_consistent_length(X, y)\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, reset)\u001b[39m\n\u001b[32m    270\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.is_categorical_ \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m             self._preprocessor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    272\u001b[39m             self._is_categorical_remapped = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    273\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m             X = validate_data(self, X, **check_X_kwargs)\n\u001b[32m    275\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m X, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    276\u001b[39m \n\u001b[32m    277\u001b[39m         n_features = X.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Hyundai'"
     ]
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a41a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = model.predict(x_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_exp = np.expm1(y_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_exp, y_pred)\n",
    "rmse = root_mean_squared_error(y_test_exp, y_pred)\n",
    "r2 = r2_score(y_test_exp, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
